---
title: "클러스터링 분석을 활용한 보험 고객 세분화"
date: "2025-02-17"
category: "analysis"
tags: ["클러스터링", "고객세분화", "보험분석"]
excerpt: "클러스터링 분석의 이론적 배경과 보험 고객 세분화에서의 활용법을 살펴보고, 실무 적용 사례를 제공합니다."
---

클러스터링 분석(Clustering Analysis)은 보험업계에서 고객을 유사한 특성을 가진 그룹으로 분류하는 핵심 기법입니다. 이번 포스트에서는 클러스터링 분석의 이론적 배경과 보험 고객 세분화에서의 실무적 활용법을 자세히 살펴보겠습니다.

## 클러스터링 분석의 정의와 목적

클러스터링 분석은 유사한 특성을 가진 객체들을 그룹으로 분류하는 비지도 학습 방법입니다:

### 1. 클러스터링의 목적

- **고객 세분화**: 유사한 특성을 가진 고객 그룹 분류
- **패턴 발견**: 데이터에서 숨겨진 패턴 발견
- **시장 분석**: 시장 세분화 및 타겟팅
- **리스크 관리**: 위험도별 고객 분류

### 2. 주요 클러스터링 알고리즘

- **K-means**: 중심 기반 클러스터링
- **계층적 클러스터링**: 트리 구조 클러스터링
- **DBSCAN**: 밀도 기반 클러스터링
- **가우시안 혼합모델**: 확률적 클러스터링

## 보험업계에서의 클러스터링 분석 활용

### 1. 주요 활용 영역

- **고객 세분화**: 보험 고객의 위험도별 분류
- **보험료 산출**: 고객 그룹별 차별화된 보험료 산출
- **마케팅**: 타겟 고객 그룹별 마케팅 전략
- **리스크 관리**: 위험도별 고객 관리

### 2. 파이썬을 활용한 클러스터링 분석

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import warnings
warnings.filterwarnings('ignore')

# 보험 고객 데이터 생성 (예시)
np.random.seed(42)
n_customers = 1000

# 고객 특성
age = np.random.normal(35, 10, n_customers)
driving_experience = np.random.normal(10, 5, n_customers)
car_value = np.random.normal(20000, 5000, n_customers)
claims_history = np.random.poisson(2, n_customers)
premium_paid = np.random.normal(1000, 200, n_customers)

# 데이터프레임 생성
data = pd.DataFrame({
    'age': age,
    'driving_experience': driving_experience,
    'car_value': car_value,
    'claims_history': claims_history,
    'premium_paid': premium_paid
})

print("보험 고객 데이터 기본 통계:")
print(data.describe())
```

### 3. K-means 클러스터링

```python
def kmeans_clustering(data, n_clusters=3):
    """K-means 클러스터링"""
    
    # 데이터 정규화
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    
    # K-means 클러스터링
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(data_scaled)
    
    # 클러스터 중심
    centers = kmeans.cluster_centers_
    
    # 실루엣 점수
    silhouette_avg = silhouette_score(data_scaled, clusters)
    
    print(f"K-means 클러스터링 결과:")
    print(f"  클러스터 수: {n_clusters}")
    print(f"  실루엣 점수: {silhouette_avg:.3f}")
    
    return clusters, centers, silhouette_avg

# K-means 클러스터링 실행
kmeans_clusters, kmeans_centers, kmeans_silhouette = kmeans_clustering(data, n_clusters=3)
```

### 4. 계층적 클러스터링

```python
def hierarchical_clustering(data, n_clusters=3):
    """계층적 클러스터링"""
    
    # 데이터 정규화
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    
    # 계층적 클러스터링
    hierarchical = AgglomerativeClustering(n_clusters=n_clusters)
    clusters = hierarchical.fit_predict(data_scaled)
    
    # 실루엣 점수
    silhouette_avg = silhouette_score(data_scaled, clusters)
    
    print(f"계층적 클러스터링 결과:")
    print(f"  클러스터 수: {n_clusters}")
    print(f"  실루엣 점수: {silhouette_avg:.3f}")
    
    return clusters, silhouette_avg

# 계층적 클러스터링 실행
hierarchical_clusters, hierarchical_silhouette = hierarchical_clustering(data, n_clusters=3)
```

## 엑셀을 활용한 클러스터링 분석

### 1. 기본 설정

```excel
A1: 고객ID
B1: 나이
C1: 운전경력
D1: 차량가격
E1: 사고이력
F1: 보험료

A2: =ROW()-1
B2: =RAND()*50+20
C2: =RAND()*20+1
D2: =RAND()*30000+10000
E2: =POISSON.DIST(RAND(),2,TRUE)
F2: =RAND()*400+800
```

### 2. K-means 클러스터링

```excel
# 클러스터 중심 초기화
A10: 클러스터
B10: 나이중심
C10: 운전경력중심
D10: 차량가격중심
E10: 사고이력중심
F10: 보험료중심

A11: 1
B11: =AVERAGE(B2:B334)
C11: =AVERAGE(C2:C334)
D11: =AVERAGE(D2:D334)
E11: =AVERAGE(E2:E334)
F11: =AVERAGE(F2:F334)

A12: 2
B12: =AVERAGE(B335:B667)
C12: =AVERAGE(C335:C667)
D12: =AVERAGE(D335:D667)
E12: =AVERAGE(E335:E667)
F12: =AVERAGE(F335:F667)

A13: 3
B13: =AVERAGE(B668:B1000)
C13: =AVERAGE(C668:C1000)
D13: =AVERAGE(D668:D1000)
E13: =AVERAGE(E668:E1000)
F13: =AVERAGE(F668:F1000)
```

### 3. 클러스터 할당

```excel
# 거리 계산
A15: 고객ID
B15: 클러스터1거리
C15: 클러스터2거리
D15: 클러스터3거리
E15: 할당클러스터

A16: =A2
B16: =SQRT((B2-B11)^2+(C2-C11)^2+(D2-D11)^2+(E2-E11)^2+(F2-F11)^2)
C16: =SQRT((B2-B12)^2+(C2-C12)^2+(D2-D12)^2+(E2-E12)^2+(F2-F12)^2)
D16: =SQRT((B2-B13)^2+(C2-C13)^2+(D2-D13)^2+(E2-E13)^2+(F2-F13)^2)
E16: =IF(B16=MIN(B16:D16),1,IF(C16=MIN(B16:D16),2,3))
```

## 고급 분석 기법

### 1. 최적 클러스터 수 결정

```python
def optimal_clusters(data, max_clusters=10):
    """최적 클러스터 수 결정"""
    
    # 데이터 정규화
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    
    # 클러스터 수별 실루엣 점수 계산
    silhouette_scores = []
    calinski_scores = []
    
    for n_clusters in range(2, max_clusters + 1):
        # K-means 클러스터링
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(data_scaled)
        
        # 실루엣 점수
        silhouette_avg = silhouette_score(data_scaled, clusters)
        silhouette_scores.append(silhouette_avg)
        
        # Calinski-Harabasz 점수
        calinski_avg = calinski_harabasz_score(data_scaled, clusters)
        calinski_scores.append(calinski_avg)
    
    # 최적 클러스터 수
    optimal_clusters = np.argmax(silhouette_scores) + 2
    
    print(f"최적 클러스터 수: {optimal_clusters}")
    print(f"최대 실루엣 점수: {max(silhouette_scores):.3f}")
    
    return optimal_clusters, silhouette_scores, calinski_scores

# 최적 클러스터 수 결정 실행
optimal_n, silhouette_scores, calinski_scores = optimal_clusters(data)
```

### 2. 혼합모델 클러스터링

```python
def gaussian_mixture_clustering(data, n_components=3):
    """가우시안 혼합모델 클러스터링"""
    
    # 데이터 정규화
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    
    # 가우시안 혼합모델
    gmm = GaussianMixture(n_components=n_components, random_state=42)
    clusters = gmm.fit_predict(data_scaled)
    
    # 확률 분포
    probabilities = gmm.predict_proba(data_scaled)
    
    # 실루엣 점수
    silhouette_avg = silhouette_score(data_scaled, clusters)
    
    print(f"가우시안 혼합모델 클러스터링 결과:")
    print(f"  컴포넌트 수: {n_components}")
    print(f"  실루엣 점수: {silhouette_avg:.3f}")
    
    return clusters, probabilities, silhouette_avg

# 가우시안 혼합모델 클러스터링 실행
gmm_clusters, gmm_probabilities, gmm_silhouette = gaussian_mixture_clustering(data, n_components=3)
```

## 실무 적용 사례

### 사례 1: 자동차보험 고객 세분화

```python
def auto_insurance_customer_segmentation():
    """자동차보험 고객 세분화"""
    
    # 실제 자동차보험 데이터 (예시)
    np.random.seed(42)
    n_customers = 2000
    
    # 고객 특성
    age = np.random.normal(35, 10, n_customers)
    driving_experience = np.random.normal(10, 5, n_customers)
    car_value = np.random.normal(20000, 5000, n_customers)
    claims_history = np.random.poisson(2, n_customers)
    premium_paid = np.random.normal(1000, 200, n_customers)
    
    # 데이터프레임 생성
    data = pd.DataFrame({
        'age': age,
        'driving_experience': driving_experience,
        'car_value': car_value,
        'claims_history': claims_history,
        'premium_paid': premium_paid
    })
    
    # K-means 클러스터링
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    
    kmeans = KMeans(n_clusters=4, random_state=42)
    clusters = kmeans.fit_predict(data_scaled)
    
    # 클러스터별 특성 분석
    data['cluster'] = clusters
    
    print("자동차보험 고객 세분화 결과:")
    for cluster in range(4):
        cluster_data = data[data['cluster'] == cluster]
        print(f"\n클러스터 {cluster + 1} ({len(cluster_data)}명):")
        print(f"  평균 나이: {cluster_data['age'].mean():.1f}")
        print(f"  평균 운전경력: {cluster_data['driving_experience'].mean():.1f}")
        print(f"  평균 차량가격: {cluster_data['car_value'].mean():.0f}")
        print(f"  평균 사고이력: {cluster_data['claims_history'].mean():.1f}")
        print(f"  평균 보험료: {cluster_data['premium_paid'].mean():.0f}")
    
    return data, clusters

# 자동차보험 고객 세분화 실행
customer_segmentation = auto_insurance_customer_segmentation()
```

### 사례 2: 보험료 산출 시스템

```python
def premium_calculation_with_clustering(model, customer_data):
    """클러스터링을 통한 보험료 산출 시스템"""
    
    # 고객 데이터 정규화
    scaler = StandardScaler()
    customer_scaled = scaler.fit_transform([customer_data])
    
    # 클러스터 예측
    cluster = model.predict(customer_scaled)[0]
    
    # 클러스터별 보험료 계수
    cluster_multipliers = {
        0: 0.8,   # 저위험
        1: 1.0,   # 중위험
        2: 1.2,   # 고위험
        3: 1.5    # 최고위험
    }
    
    # 기본 보험료
    base_premium = 1000
    
    # 클러스터별 보험료 계산
    cluster_multiplier = cluster_multipliers[cluster]
    total_premium = base_premium * cluster_multiplier
    
    return {
        'cluster': cluster,
        'cluster_multiplier': cluster_multiplier,
        'base_premium': base_premium,
        'total_premium': total_premium
    }

# 보험료 산출 시스템 실행
customer_data = [30, 5, 25000, 1, 1000]  # [나이, 운전경력, 차량가격, 사고이력, 보험료]
premium_result = premium_calculation_with_clustering(kmeans, customer_data)
for key, value in premium_result.items():
    print(f"{key}: {value}")
```

## 클러스터링 분석의 한계와 주의사항

### 1. 클러스터링 분석의 한계

- **클러스터 수**: 최적 클러스터 수 결정의 어려움
- **해석**: 클러스터의 의미 해석의 어려움
- **안정성**: 초기값에 따른 결과의 불안정성

### 2. 주의사항

- **데이터 전처리**: 데이터 정규화가 중요
- **특성 선택**: 관련 없는 특성 제거
- **검증**: 클러스터링 결과의 검증 필요

## 결론

클러스터링 분석은 보험업계에서 고객 세분화의 핵심 기법입니다. 특히 고객 분류, 보험료 산출, 마케팅 전략 수립에 직접적으로 활용할 수 있습니다.

다음 포스트에서는 주성분 분석을 활용한 보험 모델링에 대해 살펴보겠습니다.

## 참고자료

- [Real Statistics - Miscellaneous](https://real-statistics.com/miscellaneous/)
- Klugman, S. A., Panjer, H. H., & Willmot, G. E. (2012). Loss Models: From Data to Decisions
- Kaas, R., Goovaerts, M., Dhaene, J., & Denuit, M. (2008). Modern Actuarial Risk Theory
