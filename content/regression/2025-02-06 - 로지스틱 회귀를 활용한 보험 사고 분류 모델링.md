---
title: "로지스틱 회귀를 활용한 보험 사고 분류 모델링"
date: "2025-02-06"
category: "regression"
tags: ["로지스틱회귀", "분류", "보험사고"]
excerpt: "로지스틱 회귀의 이론적 배경과 보험 사고 분류에서의 활용법을 살펴보고, 실무 적용 사례를 제공합니다."
---

로지스틱 회귀(Logistic Regression)는 보험업계에서 사고 발생 여부를 예측하는 데 매우 유용한 분류 모델입니다. 이번 포스트에서는 로지스틱 회귀의 이론적 배경과 보험 사고 분류에서의 실무적 활용법을 자세히 살펴보겠습니다.

## 로지스틱 회귀의 정의와 특성

로지스틱 회귀는 종속변수가 이진(binary) 변수일 때 사용하는 회귀 분석 방법입니다:

```
P(Y=1|X) = 1 / (1 + e^(-(β₀ + β₁X₁ + β₂X₂ + ... + βₙXₙ)))
```

여기서:
- **Y**: 이진 종속변수 (사고 발생 여부: 0 또는 1)
- **X₁, X₂, ..., Xₙ**: 독립변수 (위험요인들)
- **P(Y=1|X)**: 사고 발생 확률
- **β₀, β₁, ..., βₙ**: 로지스틱 회귀계수

### 로지스틱 회귀의 주요 특성

1. **확률 출력**: 0과 1 사이의 확률값 제공
2. **비선형 관계**: 로지스틱 함수를 통한 비선형 모델링
3. **해석 가능성**: 오즈비(Odds Ratio)를 통한 직관적 해석
4. **분류 성능**: 임계값을 통한 이진 분류

## 보험업계에서의 로지스틱 회귀 활용

### 1. 보험 사고 분류 모델

로지스틱 회귀가 보험업계에서 활용되는 주요 영역:

- **자동차보험**: 사고 발생 여부 예측
- **건강보험**: 질병 발생 위험도 평가
- **생명보험**: 사망 위험도 평가
- **재산보험**: 손해 발생 여부 예측

### 2. 파이썬을 활용한 로지스틱 회귀 모델링

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import seaborn as sns

# 보험 사고 데이터 생성 (예시)
np.random.seed(42)
n_samples = 1000

# 독립변수들
age = np.random.normal(35, 10, n_samples)
driving_experience = np.random.normal(10, 5, n_samples)
car_value = np.random.normal(20000, 5000, n_samples)
claims_history = np.random.poisson(2, n_samples)
weather_risk = np.random.uniform(0, 1, n_samples)

# 사고 발생 확률 계산 (로지스틱 함수)
logit = (-2 + 0.05*age - 0.1*driving_experience + 0.0001*car_value + 
         0.3*claims_history + 0.5*weather_risk + np.random.normal(0, 0.5, n_samples))
accident_prob = 1 / (1 + np.exp(-logit))

# 이진 종속변수 생성
accident_occurred = (accident_prob > 0.5).astype(int)

# 데이터프레임 생성
data = pd.DataFrame({
    'age': age,
    'driving_experience': driving_experience,
    'car_value': car_value,
    'claims_history': claims_history,
    'weather_risk': weather_risk,
    'accident_occurred': accident_occurred,
    'accident_prob': accident_prob
})

print("데이터 기본 통계:")
print(data.describe())
print(f"\n사고 발생률: {data['accident_occurred'].mean():.3f}")
```

### 3. 모델 구축 및 평가

```python
def build_logistic_regression_model(data):
    """로지스틱 회귀 모델 구축 및 평가"""
    
    # 특성과 타겟 분리
    X = data[['age', 'driving_experience', 'car_value', 'claims_history', 'weather_risk']]
    y = data['accident_occurred']
    
    # 훈련/테스트 데이터 분할
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # 로지스틱 회귀 모델 훈련
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X_train, y_train)
    
    # 예측
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # 모델 평가
    print("분류 성능 평가:")
    print(classification_report(y_test, y_pred))
    
    # ROC AUC 점수
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    print(f"ROC AUC 점수: {roc_auc:.4f}")
    
    # 회귀계수 출력
    feature_names = X.columns
    coefficients = model.coef_[0]
    intercept = model.intercept_[0]
    
    print("\n로지스틱 회귀계수:")
    print(f"절편: {intercept:.4f}")
    for name, coef in zip(feature_names, coefficients):
        print(f"{name}: {coef:.4f}")
    
    # 오즈비 계산
    print("\n오즈비 (Odds Ratio):")
    for name, coef in zip(feature_names, coefficients):
        odds_ratio = np.exp(coef)
        print(f"{name}: {odds_ratio:.4f}")
    
    return model, X_test, y_test, y_pred, y_pred_proba

# 모델 구축 및 평가
model, X_test, y_test, y_pred, y_pred_proba = build_logistic_regression_model(data)
```

### 4. 시각화 및 분석

```python
def visualize_logistic_regression_results(X_test, y_test, y_pred, y_pred_proba):
    """로지스틱 회귀 결과 시각화"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # 혼동 행렬
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)
    ax1.set_title('혼동 행렬')
    ax1.set_xlabel('예측값')
    ax1.set_ylabel('실제값')
    
    # ROC 곡선
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC 곡선 (AUC = {roc_auc_score(y_test, y_pred_proba):.3f})')
    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='무작위 분류기')
    ax2.set_xlim([0.0, 1.0])
    ax2.set_ylim([0.0, 1.05])
    ax2.set_xlabel('거짓 양성 비율 (FPR)')
    ax2.set_ylabel('참 양성 비율 (TPR)')
    ax2.set_title('ROC 곡선')
    ax2.legend(loc="lower right")
    ax2.grid(True, alpha=0.3)
    
    # 예측 확률 분포
    ax3.hist(y_pred_proba[y_test == 0], bins=30, alpha=0.7, label='사고 없음', color='skyblue')
    ax3.hist(y_pred_proba[y_test == 1], bins=30, alpha=0.7, label='사고 있음', color='orange')
    ax3.set_xlabel('예측 확률')
    ax3.set_ylabel('빈도')
    ax3.set_title('예측 확률 분포')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 특성 중요도
    feature_importance = np.abs(model.coef_[0])
    feature_names = X_test.columns
    ax4.barh(feature_names, feature_importance)
    ax4.set_xlabel('특성 중요도 (절댓값)')
    ax4.set_title('특성 중요도')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# 시각화 실행
visualize_logistic_regression_results(X_test, y_test, y_pred, y_pred_proba)
```

## 엑셀을 활용한 로지스틱 회귀 분석

### 1. 기본 설정

```excel
A1: 나이
B1: 운전경력
C1: 차량가격
D1: 사고이력
E1: 날씨위험
F1: 사고발생
```

### 2. 로지스틱 회귀 함수 활용

```excel
# 로지스틱 회귀 확률 계산
A5: =1/(1+EXP(-(절편 + 나이계수*A2 + 운전경력계수*B2 + 차량가격계수*C2 + 사고이력계수*D2 + 날씨위험계수*E2)))

# 임계값을 통한 분류
A6: =IF(A5>0.5, 1, 0)
```

### 3. 모델 성능 평가

```excel
A10: 정확도
B10: =SUMPRODUCT((F2:F1001=A6:A1005)*1)/COUNT(F2:F1001)

A11: 정밀도
B11: =SUMPRODUCT((F2:F1001=1)*(A6:A1005=1)*1)/SUMPRODUCT((A6:A1005=1)*1)

A12: 재현율
B12: =SUMPRODUCT((F2:F1001=1)*(A6:A1005=1)*1)/SUMPRODUCT((F2:F1001=1)*1)
```

## 고급 분석 기법

### 1. 교차 검증

```python
def cross_validation_logistic_regression(X, y, cv=5):
    """교차 검증을 통한 로지스틱 회귀 모델 평가"""
    
    from sklearn.model_selection import cross_val_score, StratifiedKFold
    
    # 계층화된 K-폴드 교차 검증
    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)
    
    # 교차 검증 점수 계산
    cv_scores = cross_val_score(LogisticRegression(random_state=42, max_iter=1000), 
                               X, y, cv=skf, scoring='roc_auc')
    
    print(f"교차 검증 ROC AUC 점수:")
    print(f"평균: {cv_scores.mean():.4f}")
    print(f"표준편차: {cv_scores.std():.4f}")
    print(f"95% 신뢰구간: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]")
    
    return cv_scores

# 교차 검증 실행
X = data[['age', 'driving_experience', 'car_value', 'claims_history', 'weather_risk']]
y = data['accident_occurred']
cv_scores = cross_validation_logistic_regression(X, y)
```

### 2. 특성 선택

```python
def feature_selection_logistic_regression(X, y):
    """특성 선택을 통한 로지스틱 회귀 모델 최적화"""
    
    from sklearn.feature_selection import SelectKBest, f_classif
    from sklearn.feature_selection import RFE
    
    # 1. 통계적 특성 선택
    selector = SelectKBest(score_func=f_classif, k=3)
    X_selected = selector.fit_transform(X, y)
    
    selected_features = X.columns[selector.get_support()]
    print("통계적 특성 선택 결과:")
    print(selected_features.tolist())
    
    # 2. 재귀적 특성 제거 (RFE)
    rfe = RFE(LogisticRegression(random_state=42, max_iter=1000), n_features_to_select=3)
    rfe.fit(X, y)
    
    rfe_features = X.columns[rfe.support_]
    print("\nRFE 특성 선택 결과:")
    print(rfe_features.tolist())
    
    return selected_features, rfe_features

# 특성 선택 실행
selected_features, rfe_features = feature_selection_logistic_regression(X, y)
```

## 실무 적용 사례

### 사례 1: 자동차보험 사고 예측 시스템

```python
def auto_insurance_accident_prediction():
    """자동차보험 사고 예측 시스템"""
    
    # 실제 자동차보험 데이터 (예시)
    auto_data = pd.DataFrame({
        'age': np.random.normal(35, 10, 1000),
        'driving_experience': np.random.normal(10, 5, 1000),
        'car_value': np.random.normal(20000, 5000, 1000),
        'claims_history': np.random.poisson(2, 1000),
        'weather_risk': np.random.uniform(0, 1, 1000),
        'accident_occurred': np.random.binomial(1, 0.3, 1000)
    })
    
    # 모델 구축
    X = auto_data[['age', 'driving_experience', 'car_value', 'claims_history', 'weather_risk']]
    y = auto_data['accident_occurred']
    
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X, y)
    
    # 새로운 고객 사고 위험도 예측
    new_customer = pd.DataFrame({
        'age': [30],
        'driving_experience': [5],
        'car_value': [25000],
        'claims_history': [1],
        'weather_risk': [0.7]
    })
    
    accident_prob = model.predict_proba(new_customer)[0, 1]
    print(f"사고 발생 확률: {accident_prob:.4f}")
    
    if accident_prob > 0.5:
        print("고위험 고객으로 분류")
    else:
        print("저위험 고객으로 분류")
    
    return model, accident_prob

# 자동차보험 사고 예측 실행
auto_model, accident_prob = auto_insurance_accident_prediction()
```

### 사례 2: 보험료 산출 시스템

```python
def premium_calculation_with_risk_assessment(model, customer_data):
    """위험도 평가를 통한 보험료 산출 시스템"""
    
    # 사고 발생 확률 계산
    accident_prob = model.predict_proba(customer_data)[0, 1]
    
    # 기본 보험료
    base_premium = 1000
    
    # 위험도에 따른 보험료 조정
    if accident_prob > 0.7:
        risk_multiplier = 2.0
        risk_level = "고위험"
    elif accident_prob > 0.4:
        risk_multiplier = 1.5
        risk_level = "중위험"
    else:
        risk_multiplier = 1.0
        risk_level = "저위험"
    
    # 총 보험료 계산
    total_premium = base_premium * risk_multiplier
    
    return {
        'accident_prob': accident_prob,
        'risk_level': risk_level,
        'risk_multiplier': risk_multiplier,
        'base_premium': base_premium,
        'total_premium': total_premium
    }

# 보험료 산출 시스템 실행
customer_data = pd.DataFrame({
    'age': [30],
    'driving_experience': [5],
    'car_value': [25000],
    'claims_history': [1],
    'weather_risk': [0.7]
})

premium_result = premium_calculation_with_risk_assessment(model, customer_data)
for key, value in premium_result.items():
    print(f"{key}: {value}")
```

## 로지스틱 회귀의 한계와 대안

### 1. 로지스틱 회귀의 한계

- **선형 관계 가정**: 복잡한 비선형 관계 모델링 어려움
- **독립성 가정**: 변수 간의 상호작용 모델링 한계
- **클래스 불균형**: 불균형 데이터에서의 성능 저하

### 2. 대안 모델들

- **랜덤포레스트**: 비선형 관계와 복잡한 상호작용 모델링
- **XGBoost**: 클래스 불균형과 과적합 문제 해결
- **신경망**: 복잡한 비선형 관계 모델링
- **앙상블**: 여러 모델의 조합을 통한 성능 향상

## 결론

로지스틱 회귀는 보험업계에서 사고 발생 여부를 예측하는 데 매우 유용한 분류 모델입니다. 특히 해석 가능성이 높아 보험료 산출과 위험도 평가에 직접적으로 활용할 수 있습니다.

다음 포스트에서는 다항 로지스틱 회귀와 순서형 로지스틱 회귀를 활용한 보험 모델링에 대해 살펴보겠습니다.

## 참고자료

- [Real Statistics - Regression Models](https://real-statistics.com/regression-models/)
- Klugman, S. A., Panjer, H. H., & Willmot, G. E. (2012). Loss Models: From Data to Decisions
- Kaas, R., Goovaerts, M., Dhaene, J., & Denuit, M. (2008). Modern Actuarial Risk Theory
